{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e15b135e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No CUDA support\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas import read_csv\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torch.nn.functional import normalize\n",
    "\n",
    "print('CUDA support') if torch.cuda.is_available() else print('No CUDA support') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098dbbe5",
   "metadata": {},
   "source": [
    "### Dataloader\n",
    "PyTorch makes it a bit harder to load in custom data.  \n",
    "I will read the data with pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92f4ad7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read csv file\n",
    "math_df = pd.read_csv(\"../Data/Math_Test_Results_Cleaned.csv\")\n",
    "\n",
    "# X -> features  \n",
    "# y -> labels\n",
    "X = math_df.drop('Mean Scale Score', axis=1)\n",
    "y = math_df['Mean Scale Score']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decab131",
   "metadata": {},
   "source": [
    "Next create a custom dataset  \n",
    "This just converts the X and y values to torch tensors and wraps it in a class  \n",
    "Not really needed in this simple case but just following the guidelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab849355",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MathDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X.values)\n",
    "        self.y = torch.tensor(y)\n",
    "        \n",
    "        self.X = self.X.to(torch.float32)\n",
    "        self.y = self.y.to(torch.float32)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (self.X[idx], self.y[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a977b490",
   "metadata": {},
   "source": [
    "Use the class to process the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a166e59c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of the dataset is: 25391\n"
     ]
    }
   ],
   "source": [
    "torch_dataset = MathDataset(X, y)\n",
    "print(\"length of the dataset is:\", len(torch_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d59d0ae4",
   "metadata": {},
   "source": [
    "Split the data into train and test data, the pytorch way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "458c87b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of train data is: 20000\n",
      "The length of test data is: 5391\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data = random_split(torch_dataset, [20000, 5391])\n",
    "\n",
    "print(\"The length of train data is:\",len(train_data))\n",
    "print(\"The length of test data is:\",len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5767352f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([7.0000e+00, 2.0090e+03, 3.4000e+02, 1.0000e+00, 3.0000e-01, 1.6000e+01,\n",
      "        4.7000e+00, 1.9200e+02, 5.6500e+01, 1.3100e+02, 3.8500e+01, 3.0000e+01,\n",
      "        3.0000e+00, 1.4100e+02]), tensor(691.))\n"
     ]
    }
   ],
   "source": [
    "print(train_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d18b023b",
   "metadata": {},
   "source": [
    "This data is not normalized yet.  \n",
    "I will do this with the sklearn StandardScaler.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c84fb6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "train_data.dataset.X = scaler.fit_transform(train_data.dataset.X)\n",
    "test_data.dataset.X = scaler.transform(test_data.dataset.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "16a7adc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([-2.44268935e+00, -1.00857901e+03, -1.19035767e+00, -7.16707292e-01,\n",
      "       -8.14968359e-01, -9.19924737e-01, -1.65946676e+00, -1.05567443e+00,\n",
      "       -2.57980308e+00, -6.41264235e-01, -1.04929359e+00, -1.21812497e+00,\n",
      "       -5.59778364e-01, -1.22071398e+00]), tensor(691.))\n"
     ]
    }
   ],
   "source": [
    "print(train_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c693084",
   "metadata": {},
   "source": [
    "There we go!  \n",
    "Next I will need mini-batches  \n",
    "This is done with the DataLoader class to make things simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ead0ac98",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=train_data, batch_size=50, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_data, batch_size=20, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116a85af",
   "metadata": {},
   "source": [
    "Now we have our data ready for use.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835e9bde",
   "metadata": {},
   "source": [
    "### First modelling\n",
    "In Pytorch, this is also done in a seperate class  \n",
    "This one inherits from the Module class  \n",
    "I will start with a very simple linear model to get the pipeline started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3d368a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearModel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LinearModel, self).__init__()\n",
    "        self.linear = torch.nn.Linear(14, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        y = self.linear(x).to(torch.float32)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3653930",
   "metadata": {},
   "source": [
    "We also need a class that trains our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d1501e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_train_step(model, loss_fn, optimizer):\n",
    "    def train_step(x, y):\n",
    "        model.train()\n",
    "        optimizer.zero_grad() # Clear the gradients\n",
    "        yres = model(x) # Compute model output\n",
    "        loss = loss_fn(y, yres) # Calculate loss\n",
    "        loss.backward() # Backpropagating the error\n",
    "        optimizer.step() # Update parameters (weights)\n",
    "        return loss.item()\n",
    "    return train_step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64fe52ef",
   "metadata": {},
   "source": [
    "And this is a simple implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e125a97d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "790372.6875\n",
      "326958982365184.0\n",
      "1.3532770143253578e+23\n",
      "5.600640452272461e+31\n",
      "inf\n",
      "inf\n",
      "inf\n",
      "inf\n",
      "inf\n",
      "inf\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brechtl/miniconda3/envs/aiframeworks/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([50, 1])) that is different to the input size (torch.Size([50])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n"
     ]
    }
   ],
   "source": [
    "model = LinearModel()\n",
    "loss_fn = torch.nn.MSELoss(reduction='mean')\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "train_step = make_train_step(model, loss_fn, optimizer)\n",
    "\n",
    "for x_batch, y_batch in train_loader:\n",
    "    loss = train_step(x_batch.to(torch.float32), y_batch)\n",
    "    print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef0fe68",
   "metadata": {},
   "source": [
    "Mmh... this is an exploding gradient.  \n",
    "There is probably something wrong with the data and not the model because this is just a very simple linear model.  \n",
    "Let's look at the data again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a9e05a25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-3.90454249e+00, -1.00933504e+03, -1.22474556e+00, -7.12020905e-01,\n",
       "       -7.86946161e-01, -9.24670015e-01, -1.57459180e+00, -1.14464435e+00,\n",
       "       -2.59894656e+00, -7.50612992e-01, -1.11641478e+00, -1.34497354e+00,\n",
       "       -2.86343473e+00, -1.22606984e+00])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.dataset.X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "297e3350",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-73.31579732283028\n",
      "259.3916008613597\n"
     ]
    }
   ],
   "source": [
    "print(train_data.dataset.X.mean())\n",
    "print(train_data.dataset.X.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bde03d5",
   "metadata": {},
   "source": [
    "The data should be normalized but there is a weird outlier value (Year) and the mean/std is also not good.  \n",
    "Load the data again to begin with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4073d6bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(182.1150)\n",
      "tensor(511.6770)\n"
     ]
    }
   ],
   "source": [
    "math_df = pd.read_csv(\"../Data/Math_Test_Results_Cleaned.csv\")\n",
    "X = math_df.drop('Mean Scale Score', axis=1)\n",
    "y = math_df['Mean Scale Score']\n",
    "\n",
    "torch_dataset = MathDataset(X, y)\n",
    "train_data, test_data = random_split(torch_dataset, [20000, 5391])\n",
    "\n",
    "print(train_data.dataset.X.mean())\n",
    "print(train_data.dataset.X.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc7ce72",
   "metadata": {},
   "source": [
    "And now normalize with the implemented normalize function in Pytorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b87d887c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0048)\n",
      "tensor(0.0040)\n"
     ]
    }
   ],
   "source": [
    "train_data.dataset.X = normalize(train_data.dataset.X, p=2.0, dim=0)\n",
    "test_data.dataset.X = normalize(test_data.dataset.X, p=2.0, dim=0)\n",
    "\n",
    "print(train_data.dataset.X.mean())\n",
    "print(train_data.dataset.X.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ec880388",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=train_data, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_data, batch_size=80, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b591485c",
   "metadata": {},
   "source": [
    "Much better. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "253080c2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0035, 0.0063, 0.0054, 0.0032, 0.0027, 0.0036, 0.0040, 0.0079, 0.0090,\n",
      "        0.0013, 0.0016, 0.0075, 0.0090, 0.0035])\n",
      "epoch 0, MSE: 134194.671875, val MSE: 125769.8515625\n",
      "tensor([0.0058, 0.0063, 0.0022, 0.0000, 0.0000, 0.0001, 0.0004, 0.0017, 0.0047,\n",
      "        0.0049, 0.0144, 0.0067, 0.0090, 0.0050])\n",
      "epoch 1, MSE: 40070.1640625, val MSE: 38848.0859375\n",
      "tensor([0.0070, 0.0063, 0.0022, 0.0046, 0.0095, 0.0029, 0.0078, 0.0014, 0.0039,\n",
      "        0.0006, 0.0018, 0.0023, 0.0030, 0.0107])\n",
      "epoch 2, MSE: 12670.7236328125, val MSE: 11426.18359375\n",
      "tensor([0.0093, 0.0063, 0.0018, 0.0039, 0.0100, 0.0023, 0.0077, 0.0013, 0.0045,\n",
      "        0.0001, 0.0005, 0.0015, 0.0000, 0.0081])\n",
      "epoch 3, MSE: 3290.552734375, val MSE: 3745.8359375\n",
      "tensor([0.0046, 0.0063, 0.0016, 0.0000, 0.0000, 0.0011, 0.0043, 0.0012, 0.0046,\n",
      "        0.0025, 0.0102, 0.0018, 0.0030, 0.0006])\n",
      "epoch 4, MSE: 1665.5352783203125, val MSE: 1152.6820068359375\n",
      "tensor([0.0035, 0.0063, 0.0043, 0.0032, 0.0034, 0.0040, 0.0055, 0.0056, 0.0078,\n",
      "        0.0009, 0.0013, 0.0015, 0.0000, 0.0012])\n",
      "epoch 5, MSE: 633.2557983398438, val MSE: 939.52490234375\n",
      "tensor([0.0081, 0.0063, 0.0009, 0.0032, 0.0172, 0.0016, 0.0111, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0193, 0.0030, 0.0004])\n",
      "epoch 6, MSE: 427.12744140625, val MSE: 553.7052612304688\n",
      "tensor([0.0093, 0.0063, 0.0053, 0.0050, 0.0043, 0.0036, 0.0040, 0.0057, 0.0065,\n",
      "        0.0039, 0.0047, 0.0015, 0.0000, 0.0049])\n",
      "epoch 7, MSE: 442.80792236328125, val MSE: 310.2377014160156\n",
      "tensor([0.0070, 0.0063, 0.0054, 0.0007, 0.0006, 0.0049, 0.0054, 0.0046, 0.0052,\n",
      "        0.0063, 0.0075, 0.0069, 0.0090, 0.0032])\n",
      "epoch 8, MSE: 773.5872802734375, val MSE: 793.112548828125\n",
      "tensor([0.0093, 0.0063, 0.0021, 0.0014, 0.0031, 0.0029, 0.0082, 0.0016, 0.0047,\n",
      "        0.0012, 0.0037, 0.0033, 0.0060, 0.0081])\n",
      "epoch 9, MSE: 338.6938781738281, val MSE: 956.4246215820312\n",
      "tensor([0.0046, 0.0063, 0.0020, 0.0011, 0.0025, 0.0024, 0.0075, 0.0017, 0.0053,\n",
      "        0.0012, 0.0040, 0.0003, 0.0000, 0.0035])\n",
      "epoch 10, MSE: 626.7986450195312, val MSE: 555.9268188476562\n",
      "tensor([0.0093, 0.0063, 0.0106, 0.0374, 0.0162, 0.0162, 0.0092, 0.0026, 0.0015,\n",
      "        0.0004, 0.0003, 0.0026, 0.0030, 0.0104])\n",
      "epoch 11, MSE: 758.31201171875, val MSE: 439.296630859375\n",
      "tensor([0.0035, 0.0063, 0.0051, 0.0018, 0.0016, 0.0032, 0.0037, 0.0048, 0.0058,\n",
      "        0.0061, 0.0078, 0.0064, 0.0090, 0.0031])\n",
      "epoch 12, MSE: 528.1389770507812, val MSE: 339.908935546875\n",
      "tensor([0.0035, 0.0063, 0.0035, 0.0000, 0.0000, 0.0010, 0.0017, 0.0029, 0.0052,\n",
      "        0.0064, 0.0121, 0.0062, 0.0090, 0.0033])\n",
      "epoch 13, MSE: 446.4505310058594, val MSE: 709.7943725585938\n",
      "tensor([0.0046, 0.0063, 0.0027, 0.0004, 0.0006, 0.0004, 0.0010, 0.0029, 0.0067,\n",
      "        0.0042, 0.0101, 0.0062, 0.0090, 0.0023])\n",
      "epoch 14, MSE: 421.7312927246094, val MSE: 378.948486328125\n",
      "tensor([0.0081, 0.0063, 0.0017, 0.0007, 0.0019, 0.0016, 0.0054, 0.0026, 0.0092,\n",
      "        0.0000, 0.0000, 0.0054, 0.0060, 0.0075])\n",
      "epoch 15, MSE: 633.45751953125, val MSE: 469.96209716796875\n",
      "tensor([0.0070, 0.0063, 0.0027, 0.0021, 0.0036, 0.0046, 0.0101, 0.0022, 0.0049,\n",
      "        0.0004, 0.0011, 0.0003, 0.0000, 0.0036])\n",
      "epoch 16, MSE: 639.6908569335938, val MSE: 721.6067504882812\n",
      "tensor([0.0081, 0.0063, 0.0028, 0.0021, 0.0035, 0.0036, 0.0078, 0.0026, 0.0058,\n",
      "        0.0009, 0.0021, 0.0075, 0.0090, 0.0067])\n",
      "epoch 17, MSE: 348.620849609375, val MSE: 396.4493103027344\n",
      "tensor([0.0070, 0.0063, 0.0202, 0.0039, 0.0009, 0.0074, 0.0022, 0.0148, 0.0044,\n",
      "        0.0383, 0.0123, 0.0080, 0.0121, 0.0019])\n",
      "epoch 18, MSE: 354.4247131347656, val MSE: 697.4428100585938\n",
      "tensor([4.6362e-03, 6.2786e-03, 4.8566e-03, 1.0682e-03, 9.9318e-04, 2.7207e-03,\n",
      "        3.3663e-03, 4.4473e-03, 5.5787e-03, 6.7330e-03, 8.9805e-03, 7.7194e-03,\n",
      "        9.0421e-03, 5.1907e-05])\n",
      "epoch 19, MSE: 344.125, val MSE: 719.5494995117188\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Train x validation loss')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = LinearModel()\n",
    "loss_fn = torch.nn.MSELoss(reduction='mean')\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001)\n",
    "train_step = make_train_step(model, loss_fn, optimizer)\n",
    "\n",
    "losses = []\n",
    "val_losses = []\n",
    "\n",
    "for epoch in range(20):\n",
    "    for x_batch, y_batch in train_loader:\n",
    "        # unsqeeze the tensor to add another dimension\n",
    "        x_batch = x_batch.to(torch.float32)\n",
    "        y_batch = y_batch.to(torch.float32).unsqueeze(-1)\n",
    "        \n",
    "        loss = train_step(x_batch, y_batch)\n",
    "        losses.append(loss)\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        for x_val, y_val in test_loader:\n",
    "            x_val = x_val.to(torch.float32)\n",
    "            y_val = y_val.to(torch.float32).unsqueeze(-1)\n",
    "            \n",
    "            model.eval()\n",
    "\n",
    "            yhat = model(x_val)\n",
    "            val_loss = loss_fn(y_val, yhat)\n",
    "            val_losses.append(val_loss.item())\n",
    "    \n",
    "    print(x_batch[0])\n",
    "    print('epoch {}, MSE: {}, val MSE: {}'.format(epoch, loss, val_loss))\n",
    "    \n",
    "plt.plot(losses, label=\"Train loss\")\n",
    "plt.plot(val_losses, label=\"Validation loss\")\n",
    "plt.legend()\n",
    "plt.title(\"Train x validation loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9cea1c",
   "metadata": {},
   "source": [
    "Because we use the mini-batches and a simple model, it doesn't take long to reach a good model state with 'low' training and validation loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2ad05333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[673.4541]\n"
     ]
    }
   ],
   "source": [
    "# convert row to data\n",
    "row = torch.Tensor([0.0070, 0.0063, 0.0043, 0.0004, 0.0004, 0.0007, 0.0010, 0.0050, 0.0072,\n",
    "        0.0061, 0.0093, 0.0005, 0.0000, 0.0067])\n",
    "# make prediction\n",
    "yhat = model(row)\n",
    "# retrieve numpy array\n",
    "yhat = yhat.detach().numpy()\n",
    "print(yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2358f074",
   "metadata": {},
   "source": [
    "### Changing the model\n",
    "I will add some layers to the simple model.  \n",
    "The simple model did not work that well so it could be a complexity issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "50ed1683",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.init import xavier_uniform_\n",
    "\n",
    "class Regressor(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Regressor, self).__init__()\n",
    "        self.hidden1 = torch.nn.Linear(14, 10)\n",
    "        xavier_uniform_(self.hidden1.weight)\n",
    "        self.sigmoid1 = torch.nn.Sigmoid()\n",
    "        self.hidden2 = torch.nn.Linear(10, 8)\n",
    "        xavier_uniform_(self.hidden2.weight)\n",
    "        self.sigmoid2 = torch.nn.Sigmoid()\n",
    "        self.hidden3 = torch.nn.Linear(8, 1)\n",
    "        xavier_uniform_(self.hidden3.weight)\n",
    "        \n",
    "    \n",
    "    def forward(self, X):\n",
    "        # First hidden layer\n",
    "        X = self.hidden1(X)\n",
    "        X = self.sigmoid1(X)\n",
    "        # Second hidden layer\n",
    "        X = self.hidden2(X)\n",
    "        X = self.sigmoid2(X)\n",
    "        # Third hidden layer\n",
    "        X = self.hidden3(X)\n",
    "        \n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "52d6531a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, MSE: 513.1994018554688, val loss: 726.5034790039062\n",
      "epoch 1, MSE: 582.1410522460938, val loss: 466.93780517578125\n",
      "epoch 2, MSE: 312.62042236328125, val loss: 628.6344604492188\n",
      "epoch 3, MSE: 509.49493408203125, val loss: 627.052490234375\n",
      "epoch 4, MSE: 555.801025390625, val loss: 532.0841674804688\n",
      "epoch 5, MSE: 691.6475830078125, val loss: 1039.2259521484375\n",
      "epoch 6, MSE: 743.038818359375, val loss: 402.0419006347656\n",
      "epoch 7, MSE: 579.8347778320312, val loss: 566.680908203125\n",
      "epoch 8, MSE: 561.012939453125, val loss: 911.6326293945312\n",
      "epoch 9, MSE: 534.5084228515625, val loss: 301.80572509765625\n",
      "epoch 10, MSE: 515.9525146484375, val loss: 564.2644653320312\n",
      "epoch 11, MSE: 463.56048583984375, val loss: 673.2403564453125\n",
      "epoch 12, MSE: 1089.829345703125, val loss: 370.0843200683594\n",
      "epoch 13, MSE: 700.0992431640625, val loss: 514.23583984375\n",
      "epoch 14, MSE: 546.2403564453125, val loss: 430.3384094238281\n",
      "epoch 15, MSE: 679.6637573242188, val loss: 332.1888122558594\n",
      "epoch 16, MSE: 634.4907836914062, val loss: 699.8971557617188\n",
      "epoch 17, MSE: 543.107421875, val loss: 544.5196533203125\n",
      "epoch 18, MSE: 711.15771484375, val loss: 691.8054809570312\n",
      "epoch 19, MSE: 475.3531799316406, val loss: 522.8928833007812\n",
      "epoch 20, MSE: 601.6058959960938, val loss: 318.70703125\n",
      "epoch 21, MSE: 557.1370849609375, val loss: 525.2511596679688\n",
      "epoch 22, MSE: 724.069091796875, val loss: 596.5831909179688\n",
      "epoch 23, MSE: 604.5811157226562, val loss: 416.3567199707031\n",
      "epoch 24, MSE: 285.9969787597656, val loss: 565.734130859375\n",
      "epoch 25, MSE: 839.2169189453125, val loss: 449.54656982421875\n",
      "epoch 26, MSE: 590.6991577148438, val loss: 666.4186401367188\n",
      "epoch 27, MSE: 629.7925415039062, val loss: 728.1466064453125\n",
      "epoch 28, MSE: 591.3776245117188, val loss: 607.1041259765625\n",
      "epoch 29, MSE: 367.5708312988281, val loss: 1053.735595703125\n",
      "epoch 30, MSE: 581.6756591796875, val loss: 659.7421875\n",
      "epoch 31, MSE: 579.609130859375, val loss: 405.2093505859375\n",
      "epoch 32, MSE: 605.1070556640625, val loss: 713.4081420898438\n",
      "epoch 33, MSE: 722.5289916992188, val loss: 946.272705078125\n",
      "epoch 34, MSE: 599.2752685546875, val loss: 473.60540771484375\n",
      "epoch 35, MSE: 581.878662109375, val loss: 307.6663818359375\n",
      "epoch 36, MSE: 665.8470458984375, val loss: 756.6322631835938\n",
      "epoch 37, MSE: 558.95068359375, val loss: 504.6419982910156\n",
      "epoch 38, MSE: 368.1881408691406, val loss: 848.3108520507812\n",
      "epoch 39, MSE: 437.79229736328125, val loss: 648.8101196289062\n",
      "epoch 40, MSE: 715.5952758789062, val loss: 580.7951049804688\n",
      "epoch 41, MSE: 530.4210205078125, val loss: 455.316650390625\n",
      "epoch 42, MSE: 411.41156005859375, val loss: 553.5\n",
      "epoch 43, MSE: 416.7266845703125, val loss: 871.7966918945312\n",
      "epoch 44, MSE: 685.5494995117188, val loss: 640.3832397460938\n",
      "epoch 45, MSE: 730.2886962890625, val loss: 763.4600219726562\n",
      "epoch 46, MSE: 394.4775390625, val loss: 711.1712036132812\n",
      "epoch 47, MSE: 612.6656494140625, val loss: 507.2857666015625\n",
      "epoch 48, MSE: 273.8061218261719, val loss: 541.5462646484375\n",
      "epoch 49, MSE: 539.666259765625, val loss: 456.5652770996094\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Train x validation loss')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Regressor()\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001)\n",
    "train_step = make_train_step(model, loss_fn, optimizer)\n",
    "\n",
    "losses = []\n",
    "val_losses = []\n",
    "\n",
    "for epoch in range(50):\n",
    "    for x_batch, y_batch in train_loader:\n",
    "        # unsqeeze the tensor to add another dimension\n",
    "        x_batch = x_batch.to(torch.float32)\n",
    "        y_batch = y_batch.to(torch.float32).unsqueeze(-1)\n",
    "        \n",
    "        loss = train_step(x_batch, y_batch)\n",
    "        losses.append(loss)\n",
    "        \n",
    "    # Evaluate the model with test data\n",
    "    with torch.no_grad():\n",
    "        for x_val, y_val in test_loader:\n",
    "            x_val = x_val.to(torch.float32)\n",
    "            y_val = y_val.to(torch.float32).unsqueeze(-1)\n",
    "            \n",
    "            model.eval()\n",
    "\n",
    "            yhat = model(x_val)\n",
    "            val_loss = loss_fn(y_val, yhat)\n",
    "            val_losses.append(val_loss.item())\n",
    "    \n",
    "    print('epoch {}, MSE: {}, val loss: {}'.format(epoch, loss, val_loss))\n",
    "    \n",
    "plt.plot(losses, label=\"Train loss\")\n",
    "plt.plot(val_losses, label=\"Validation loss\")\n",
    "plt.legend()\n",
    "plt.title(\"Train x validation loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5d80a28f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[671.8811]\n"
     ]
    }
   ],
   "source": [
    "# convert row to data\n",
    "row = torch.Tensor([0.003, 0.000004, 011111.14, 0.0007, 0.0013, 0.0039, 0.0096, 0.0023, 0.0057,0.0006, 0.0016, 0.0059, 0.0060, 0.0046])\n",
    "# make prediction\n",
    "yhat = model(row)\n",
    "# retrieve numpy array\n",
    "yhat = yhat.detach().numpy()\n",
    "print(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "13c18a4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0093, 0.0063, 0.0234, 0.0189, 0.0037, 0.0332, 0.0085, 0.0148, 0.0038,\n",
      "        0.0163, 0.0045, 0.0075, 0.0090, 0.0062])\n",
      "tensor(675.)\n",
      "tensor([0.0046, 0.0063, 0.0036, 0.0021, 0.0027, 0.0052, 0.0086, 0.0025, 0.0042,\n",
      "        0.0024, 0.0043, 0.0069, 0.0090, 0.0027])\n",
      "tensor(679.)\n",
      "tensor([0.0058, 0.0063, 0.0083, 0.0032, 0.0018, 0.0057, 0.0041, 0.0065, 0.0048,\n",
      "        0.0115, 0.0090, 0.0062, 0.0090, 0.0032])\n",
      "tensor(695.)\n",
      "tensor([0.0081, 0.0063, 0.0055, 0.0007, 0.0006, 0.0010, 0.0011, 0.0050, 0.0055,\n",
      "        0.0102, 0.0119, 0.0005, 0.0000, 0.0066])\n",
      "tensor(695.)\n",
      "tensor([0.0035, 0.0063, 0.0066, 0.0004, 0.0002, 0.0009, 0.0008, 0.0110, 0.0101,\n",
      "        0.0048, 0.0047, 0.0077, 0.0090, 0.0055])\n",
      "tensor(689.)\n",
      "tensor([0.0093, 0.0063, 0.0131, 0.0256, 0.0090, 0.0208, 0.0095, 0.0074, 0.0034,\n",
      "        0.0018, 0.0009, 0.0080, 0.0121, 0.0013])\n",
      "tensor(656.)\n",
      "tensor([0.0058, 0.0063, 0.0090, 0.0028, 0.0015, 0.0046, 0.0031, 0.0112, 0.0076,\n",
      "        0.0079, 0.0057, 0.0069, 0.0090, 0.0028])\n",
      "tensor(693.)\n",
      "tensor([0.0093, 0.0063, 0.0104, 0.0046, 0.0020, 0.0133, 0.0077, 0.0087, 0.0051,\n",
      "        0.0070, 0.0044, 0.0077, 0.0090, 0.0053])\n",
      "tensor(678.)\n",
      "tensor([0.0035, 0.0063, 0.0069, 0.0068, 0.0045, 0.0030, 0.0026, 0.0086, 0.0076,\n",
      "        0.0048, 0.0045, 0.0046, 0.0060, 0.0063])\n",
      "tensor(669.)\n",
      "tensor([0.0058, 0.0063, 0.0036, 0.0014, 0.0018, 0.0020, 0.0033, 0.0033, 0.0056,\n",
      "        0.0048, 0.0085, 0.0054, 0.0060, 0.0026])\n",
      "tensor(681.)\n",
      "tensor([0.0070, 0.0063, 0.0017, 0.0004, 0.0010, 0.0009, 0.0031, 0.0021, 0.0076,\n",
      "        0.0015, 0.0058, 0.0010, 0.0000, 0.0015])\n",
      "tensor(676.)\n",
      "tensor([0.0035, 0.0063, 0.0020, 0.0025, 0.0057, 0.0027, 0.0081, 0.0019, 0.0058,\n",
      "        0.0001, 0.0005, 0.0039, 0.0060, 0.0007])\n",
      "tensor(646.)\n",
      "tensor([0.0058, 0.0063, 0.0021, 0.0007, 0.0015, 0.0039, 0.0109, 0.0019, 0.0054,\n",
      "        0.0001, 0.0005, 0.0041, 0.0060, 0.0006])\n",
      "tensor(671.)\n",
      "tensor([0.0058, 0.0063, 0.0059, 0.0021, 0.0016, 0.0020, 0.0020, 0.0076, 0.0079,\n",
      "        0.0057, 0.0063, 0.0064, 0.0090, 0.0028])\n",
      "tensor(678.)\n",
      "tensor([0.0058, 0.0063, 0.0055, 0.0011, 0.0009, 0.0072, 0.0078, 0.0051, 0.0057,\n",
      "        0.0033, 0.0039, 0.0069, 0.0090, 0.0023])\n",
      "tensor(682.)\n",
      "tensor([0.0081, 0.0063, 0.0124, 0.0114, 0.0042, 0.0252, 0.0122, 0.0076, 0.0037,\n",
      "        0.0006, 0.0003, 0.0026, 0.0030, 0.0063])\n",
      "tensor(637.)\n",
      "tensor([0.0070, 0.0063, 0.0051, 0.0021, 0.0019, 0.0052, 0.0060, 0.0046, 0.0055,\n",
      "        0.0043, 0.0055, 0.0072, 0.0090, 0.0043])\n",
      "tensor(683.)\n",
      "tensor([0.0058, 0.0063, 0.0028, 0.0028, 0.0046, 0.0030, 0.0064, 0.0024, 0.0051,\n",
      "        0.0018, 0.0041, 0.0033, 0.0060, 0.0024])\n",
      "tensor(679.)\n",
      "tensor([0.0058, 0.0063, 0.0022, 0.0025, 0.0052, 0.0020, 0.0054, 0.0027, 0.0076,\n",
      "        0.0003, 0.0009, 0.0077, 0.0090, 0.0029])\n",
      "tensor(655.)\n",
      "tensor([0.0093, 0.0063, 0.0037, 0.0050, 0.0062, 0.0063, 0.0103, 0.0026, 0.0043,\n",
      "        0.0001, 0.0003, 0.0031, 0.0030, 0.0056])\n",
      "tensor(658.)\n",
      "tensor([0.0035, 0.0063, 0.0050, 0.0021, 0.0019, 0.0006, 0.0007, 0.0049, 0.0060,\n",
      "        0.0082, 0.0107, 0.0057, 0.0060, 0.0013])\n",
      "tensor(697.)\n",
      "tensor([0.0046, 0.0063, 0.0060, 0.0032, 0.0024, 0.0086, 0.0086, 0.0046, 0.0047,\n",
      "        0.0034, 0.0037, 0.0036, 0.0060, 0.0065])\n",
      "tensor(678.)\n",
      "tensor([0.0093, 0.0063, 0.0119, 0.0214, 0.0082, 0.0147, 0.0074, 0.0090, 0.0046,\n",
      "        0.0033, 0.0018, 0.0028, 0.0030, 0.0047])\n",
      "tensor(642.)\n",
      "tensor([0.0046, 0.0063, 0.0018, 0.0011, 0.0027, 0.0010, 0.0033, 0.0030, 0.0101,\n",
      "        0.0001, 0.0005, 0.0059, 0.0060, 0.0086])\n",
      "tensor(663.)\n",
      "tensor([0.0046, 0.0063, 0.0029, 0.0053, 0.0086, 0.0026, 0.0054, 0.0028, 0.0061,\n",
      "        0.0006, 0.0014, 0.0026, 0.0030, 0.0010])\n",
      "tensor(649.)\n",
      "tensor([0.0093, 0.0063, 0.0293, 0.0182, 0.0028, 0.0289, 0.0059, 0.0296, 0.0062,\n",
      "        0.0181, 0.0040, 0.0062, 0.0090, 0.0019])\n",
      "tensor(663.)\n",
      "tensor([0.0046, 0.0063, 0.0069, 0.0007, 0.0005, 0.0014, 0.0012, 0.0060, 0.0053,\n",
      "        0.0130, 0.0122, 0.0064, 0.0090, 0.0006])\n",
      "tensor(709.)\n",
      "tensor([0.0081, 0.0063, 0.0021, 0.0089, 0.0195, 0.0026, 0.0074, 0.0006, 0.0017,\n",
      "        0.0000, 0.0000, 0.0193, 0.0121, 0.0006])\n",
      "tensor(606.)\n",
      "tensor([0.0093, 0.0063, 0.0232, 0.0150, 0.0029, 0.0160, 0.0042, 0.0204, 0.0054,\n",
      "        0.0262, 0.0073, 0.0051, 0.0060, 0.0052])\n",
      "tensor(677.)\n",
      "tensor([5.7952e-03, 6.2661e-03, 3.8342e-04, 2.8485e-03, 3.3959e-02, 0.0000e+00,\n",
      "        0.0000e+00, 9.4623e-05, 1.5030e-03, 0.0000e+00, 0.0000e+00, 1.9299e-02,\n",
      "        6.0281e-03, 1.3755e-03])\n",
      "tensor(606.)\n",
      "tensor([0.0046, 0.0063, 0.0020, 0.0007, 0.0016, 0.0010, 0.0029, 0.0027, 0.0082,\n",
      "        0.0015, 0.0047, 0.0026, 0.0030, 0.0010])\n",
      "tensor(674.)\n",
      "tensor([0.0058, 0.0063, 0.0037, 0.0061, 0.0074, 0.0042, 0.0067, 0.0031, 0.0051,\n",
      "        0.0013, 0.0023, 0.0023, 0.0030, 0.0034])\n",
      "tensor(660.)\n",
      "tensor([0.0081, 0.0063, 0.0021, 0.0011, 0.0023, 0.0013, 0.0037, 0.0030, 0.0088,\n",
      "        0.0007, 0.0023, 0.0059, 0.0060, 0.0043])\n",
      "tensor(660.)\n",
      "tensor([0.0035, 0.0063, 0.0012, 0.0021, 0.0085, 0.0014, 0.0075, 0.0008, 0.0040,\n",
      "        0.0004, 0.0025, 0.0003, 0.0000, 0.0049])\n",
      "tensor(677.)\n",
      "tensor([0.0081, 0.0063, 0.0163, 0.0011, 0.0003, 0.0020, 0.0007, 0.0214, 0.0080,\n",
      "        0.0209, 0.0083, 0.0082, 0.0060, 0.0099])\n",
      "tensor(688.)\n",
      "tensor([0.0058, 0.0063, 0.0023, 0.0018, 0.0035, 0.0040, 0.0103, 0.0016, 0.0042,\n",
      "        0.0007, 0.0021, 0.0013, 0.0000, 0.0050])\n",
      "tensor(651.)\n",
      "tensor([0.0058, 0.0063, 0.0052, 0.0053, 0.0047, 0.0046, 0.0052, 0.0046, 0.0054,\n",
      "        0.0040, 0.0050, 0.0075, 0.0090, 0.0031])\n",
      "tensor(663.)\n",
      "tensor([0.0093, 0.0063, 0.0227, 0.0046, 0.0009, 0.0182, 0.0048, 0.0227, 0.0061,\n",
      "        0.0230, 0.0065, 0.0036, 0.0060, 0.0083])\n",
      "tensor(688.)\n",
      "tensor([0.0081, 0.0063, 0.0024, 0.0039, 0.0074, 0.0040, 0.0099, 0.0014, 0.0036,\n",
      "        0.0004, 0.0012, 0.0010, 0.0000, 0.0099])\n",
      "tensor(655.)\n",
      "tensor([0.0046, 0.0063, 0.0048, 0.0021, 0.0021, 0.0032, 0.0040, 0.0040, 0.0051,\n",
      "        0.0063, 0.0085, 0.0080, 0.0121, 0.0003])\n",
      "tensor(695.)\n",
      "tensor([0.0046, 0.0063, 0.0015, 0.0011, 0.0032, 0.0024, 0.0095, 0.0010, 0.0041,\n",
      "        0.0007, 0.0032, 0.0013, 0.0000, 0.0024])\n",
      "tensor(668.)\n",
      "tensor([0.0093, 0.0063, 0.0023, 0.0028, 0.0058, 0.0040, 0.0106, 0.0016, 0.0043,\n",
      "        0.0000, 0.0000, 0.0008, 0.0000, 0.0064])\n",
      "tensor(639.)\n",
      "tensor([0.0046, 0.0063, 0.0026, 0.0004, 0.0006, 0.0027, 0.0064, 0.0020, 0.0047,\n",
      "        0.0028, 0.0072, 0.0069, 0.0090, 0.0012])\n",
      "tensor(694.)\n",
      "tensor([0.0058, 0.0063, 0.0048, 0.0014, 0.0014, 0.0032, 0.0040, 0.0067, 0.0086,\n",
      "        0.0022, 0.0030, 0.0062, 0.0090, 0.0062])\n",
      "tensor(669.)\n",
      "tensor([0.0070, 0.0063, 0.0165, 0.0025, 0.0007, 0.0047, 0.0017, 0.0119, 0.0044,\n",
      "        0.0332, 0.0130, 0.0080, 0.0121, 0.0002])\n",
      "tensor(704.)\n",
      "tensor([0.0093, 0.0063, 0.0028, 0.0018, 0.0029, 0.0042, 0.0090, 0.0028, 0.0063,\n",
      "        0.0001, 0.0003, 0.0044, 0.0060, 0.0047])\n",
      "tensor(647.)\n",
      "tensor([0.0058, 0.0063, 0.0051, 0.0000, 0.0000, 0.0006, 0.0007, 0.0040, 0.0048,\n",
      "        0.0109, 0.0139, 0.0051, 0.0060, 0.0048])\n",
      "tensor(709.)\n",
      "tensor([0.0035, 0.0063, 0.0056, 0.0007, 0.0006, 0.0006, 0.0006, 0.0094, 0.0102,\n",
      "        0.0040, 0.0047, 0.0080, 0.0121, 0.0003])\n",
      "tensor(688.)\n",
      "tensor([0.0093, 0.0063, 0.0062, 0.0078, 0.0058, 0.0126, 0.0122, 0.0029, 0.0029,\n",
      "        0.0006, 0.0006, 0.0036, 0.0060, 0.0013])\n",
      "tensor(657.)\n",
      "tensor([0.0093, 0.0063, 0.0058, 0.0021, 0.0017, 0.0050, 0.0051, 0.0077, 0.0080,\n",
      "        0.0022, 0.0025, 0.0031, 0.0030, 0.0025])\n",
      "tensor(665.)\n",
      "tensor([0.0035, 0.0063, 0.0025, 0.0036, 0.0065, 0.0017, 0.0041, 0.0027, 0.0067,\n",
      "        0.0012, 0.0031, 0.0013, 0.0000, 0.0050])\n",
      "tensor(661.)\n",
      "tensor([0.0081, 0.0063, 0.0276, 0.0043, 0.0007, 0.0123, 0.0027, 0.0357, 0.0079,\n",
      "        0.0259, 0.0061, 0.0069, 0.0090, 0.0055])\n",
      "tensor(677.)\n",
      "tensor([0.0070, 0.0063, 0.0077, 0.0253, 0.0150, 0.0117, 0.0091, 0.0026, 0.0021,\n",
      "        0.0000, 0.0000, 0.0015, 0.0000, 0.0084])\n",
      "tensor(618.)\n",
      "tensor([0.0035, 0.0063, 0.0016, 0.0004, 0.0010, 0.0011, 0.0043, 0.0026, 0.0100,\n",
      "        0.0001, 0.0006, 0.0003, 0.0000, 0.0036])\n",
      "tensor(668.)\n",
      "tensor([0.0070, 0.0063, 0.0065, 0.0100, 0.0070, 0.0073, 0.0068, 0.0064, 0.0061,\n",
      "        0.0007, 0.0008, 0.0039, 0.0060, 0.0035])\n",
      "tensor(644.)\n",
      "tensor([0.0070, 0.0063, 0.0017, 0.0025, 0.0068, 0.0030, 0.0108, 0.0008, 0.0028,\n",
      "        0.0004, 0.0018, 0.0010, 0.0000, 0.0013])\n",
      "tensor(657.)\n",
      "tensor([0.0058, 0.0063, 0.0024, 0.0032, 0.0062, 0.0036, 0.0090, 0.0013, 0.0034,\n",
      "        0.0012, 0.0033, 0.0008, 0.0000, 0.0054])\n",
      "tensor(665.)\n",
      "tensor([0.0046, 0.0063, 0.0062, 0.0007, 0.0005, 0.0039, 0.0037, 0.0052, 0.0051,\n",
      "        0.0091, 0.0096, 0.0062, 0.0090, 0.0059])\n",
      "tensor(704.)\n",
      "tensor([0.0081, 0.0063, 0.0021, 0.0021, 0.0047, 0.0036, 0.0103, 0.0013, 0.0039,\n",
      "        0.0006, 0.0019, 0.0044, 0.0060, 0.0092])\n",
      "tensor(665.)\n",
      "tensor([0.0046, 0.0063, 0.0031, 0.0011, 0.0016, 0.0007, 0.0014, 0.0040, 0.0079,\n",
      "        0.0033, 0.0070, 0.0028, 0.0030, 0.0028])\n",
      "tensor(689.)\n",
      "tensor([0.0070, 0.0063, 0.0162, 0.0093, 0.0026, 0.0149, 0.0055, 0.0150, 0.0056,\n",
      "        0.0139, 0.0055, 0.0075, 0.0090, 0.0028])\n",
      "tensor(682.)\n",
      "tensor([0.0070, 0.0063, 0.0029, 0.0036, 0.0056, 0.0033, 0.0068, 0.0027, 0.0058,\n",
      "        0.0009, 0.0020, 0.0064, 0.0090, 0.0057])\n",
      "tensor(654.)\n",
      "tensor([0.0058, 0.0063, 0.0038, 0.0007, 0.0008, 0.0014, 0.0022, 0.0064, 0.0102,\n",
      "        0.0015, 0.0025, 0.0072, 0.0090, 0.0053])\n",
      "tensor(671.)\n",
      "tensor([0.0035, 0.0063, 0.0041, 0.0028, 0.0032, 0.0040, 0.0059, 0.0044, 0.0065,\n",
      "        0.0021, 0.0033, 0.0080, 0.0121, 0.0010])\n",
      "tensor(689.)\n",
      "tensor([0.0035, 0.0063, 0.0013, 0.0007, 0.0025, 0.0004, 0.0020, 0.0021, 0.0096,\n",
      "        0.0006, 0.0029, 0.0003, 0.0000, 0.0004])\n",
      "tensor(672.)\n",
      "tensor([0.0058, 0.0063, 0.0049, 0.0000, 0.0000, 0.0007, 0.0009, 0.0042, 0.0052,\n",
      "        0.0099, 0.0131, 0.0067, 0.0090, 0.0057])\n",
      "tensor(713.)\n",
      "tensor([0.0093, 0.0063, 0.0030, 0.0032, 0.0049, 0.0064, 0.0130, 0.0015, 0.0031,\n",
      "        0.0000, 0.0000, 0.0049, 0.0060, 0.0176])\n",
      "tensor(659.)\n",
      "tensor([0.0046, 0.0063, 0.0011, 0.0039, 0.0168, 0.0009, 0.0048, 0.0007, 0.0038,\n",
      "        0.0001, 0.0009, 0.0193, 0.0090, 0.0002])\n",
      "tensor(624.)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for x_val, y_val in test_loader:\n",
    "    print(x_val[1])\n",
    "    print(y_val[1])\n",
    "    \n",
    "plt.plot([0.0058, 0.0063, 0.0029, 0.0000, 0.0000, 0.0001, 0.0003, 0.0029, 0.0062,\n",
    "        0.0054, 0.0120, 0.0080, 0.0121, 0.0012])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b4865b",
   "metadata": {},
   "source": [
    "### Debugging in seperate IDE\n",
    "There is clearly something else wrong.  \n",
    "I really don't like Notebooks for debugging and unit testing so I did this in Spyder IDE.  \n",
    "I knew that a linear model would give a good result and I tested this with sklearn here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "62c48941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 32.505882\n",
      "r2-score: 0.9429696296134678\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "reg = LinearRegression().fit(train_data.dataset.X, train_data.dataset.y)\n",
    "y_pred = reg.predict(test_data.dataset.X)\n",
    "print(\"MSE: \" + str(mean_squared_error(test_data.dataset.y, y_pred)))\n",
    "print(\"r2-score: \" + str(reg.score(test_data.dataset.X, test_data.dataset.y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f54994",
   "metadata": {},
   "source": [
    "And this is the full debugged model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddadfadc",
   "metadata": {},
   "source": [
    "#### Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c89df7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CSVDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, path):\n",
    "        # load the csv file as a dataframe\n",
    "        df = read_csv(path)\n",
    "        # store the inputs and outputs\n",
    "        self.X = df.drop('Mean Scale Score', axis=1)\n",
    "        self.y = df['Mean Scale Score']\n",
    "        # ensure target has the right shape\n",
    "        self.y = self.y.values.reshape((-1, 1))\n",
    "        \n",
    "        # Scale the data\n",
    "        scaler = StandardScaler()\n",
    "        self.X = scaler.fit_transform(self.X)\n",
    "        \n",
    "        self.X = torch.tensor(self.X.astype(np.float32))\n",
    "        self.y = torch.tensor(self.y.astype(np.float32))\n",
    "        \n",
    "    # number of rows in the dataset\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    " \n",
    "    # get a row at an index\n",
    "    def __getitem__(self, idx):\n",
    "        return [self.X[idx], self.y[idx]]\n",
    " \n",
    "    # get indexes for train and test rows\n",
    "    def get_splits(self, n_test=0.33):\n",
    "        # determine sizes\n",
    "        test_size = round(n_test * len(self.X))\n",
    "        train_size = len(self.X) - test_size\n",
    "        # calculate the split\n",
    "        return random_split(self, [train_size, test_size])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "522ff98c",
   "metadata": {},
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8d847f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Regressor(torch.nn.Module):\n",
    "    # define model elements\n",
    "    def __init__(self, n_inputs):\n",
    "        super(Regressor, self).__init__()\n",
    "        # input to first hidden layer\n",
    "        self.hidden1 = torch.nn.Linear(n_inputs, 1)\n",
    "\n",
    " \n",
    "    # forward propagate input\n",
    "    def forward(self, X):\n",
    "        # input to first hidden layer\n",
    "        X = self.hidden1(X)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1901f8",
   "metadata": {},
   "source": [
    "#### Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8c3d22c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(path):\n",
    "    # load the dataset\n",
    "    dataset = CSVDataset(path)\n",
    "    # calculate split\n",
    "    train, test = dataset.get_splits()\n",
    "    \n",
    "    # prepare data loaders\n",
    "    train_dl = DataLoader(train, batch_size=80, shuffle=True)\n",
    "    test_dl = DataLoader(test, batch_size=120, shuffle=False)\n",
    "    return train_dl, test_dl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a7cde9",
   "metadata": {},
   "source": [
    "#### Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b2a29deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(train_dl, model):\n",
    "    # define the optimization\n",
    "    criterion = torch.nn.MSELoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.08)\n",
    "    # enumerate epochs\n",
    "    for epoch in range(40):\n",
    "        # enumerate mini batches\n",
    "        for i, (inputs, targets) in enumerate(train_dl):\n",
    "            # clear the gradients\n",
    "            optimizer.zero_grad()\n",
    "            # compute the model output\n",
    "            yhat = model(inputs)\n",
    "            # calculate loss\n",
    "            loss = criterion(yhat, targets)\n",
    "            # credit assignment\n",
    "            loss.backward()\n",
    "            # update model weights\n",
    "            optimizer.step()\n",
    "        print('epoch {}, MSE: {}'.format(epoch, loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f96f374",
   "metadata": {},
   "source": [
    "#### Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b4a51705",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(test_dl, model):\n",
    "    predictions, actuals = list(), list()\n",
    "    for i, (inputs, targets) in enumerate(test_dl):\n",
    "        # evaluate the model on the test set\n",
    "        yhat = model(inputs)\n",
    "        # retrieve numpy array\n",
    "        yhat = yhat.detach().numpy()\n",
    "        actual = targets.numpy()\n",
    "        actual = actual.reshape((len(actual), 1))\n",
    "        # store\n",
    "        predictions.append(yhat)\n",
    "        actuals.append(actual)\n",
    "        \n",
    "        predictions, actuals = np.vstack(predictions), np.vstack(actuals)\n",
    "        \n",
    "        print(\"r2-score:\" + str(r2_score(actuals, predictions)))\n",
    "        \n",
    "        # calculate mse\n",
    "        mse = mean_squared_error(actuals, predictions)\n",
    "        return mse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b198e3b",
   "metadata": {},
   "source": [
    "#### Main code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "63a3ac65",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, MSE: 29.48101043701172\n",
      "epoch 1, MSE: 23.038066864013672\n",
      "epoch 2, MSE: 30.972501754760742\n",
      "epoch 3, MSE: 31.821786880493164\n",
      "epoch 4, MSE: 19.491575241088867\n",
      "epoch 5, MSE: 29.000083923339844\n",
      "epoch 6, MSE: 34.038578033447266\n",
      "epoch 7, MSE: 30.084585189819336\n",
      "epoch 8, MSE: 24.020633697509766\n",
      "epoch 9, MSE: 38.53847122192383\n",
      "epoch 10, MSE: 40.17539596557617\n",
      "epoch 11, MSE: 38.84812545776367\n",
      "epoch 12, MSE: 41.76333999633789\n",
      "epoch 13, MSE: 30.109004974365234\n",
      "epoch 14, MSE: 51.634727478027344\n",
      "epoch 15, MSE: 36.69435501098633\n",
      "epoch 16, MSE: 31.14822769165039\n",
      "epoch 17, MSE: 22.152584075927734\n",
      "epoch 18, MSE: 31.21400260925293\n",
      "epoch 19, MSE: 37.31541442871094\n",
      "epoch 20, MSE: 30.94044303894043\n",
      "epoch 21, MSE: 38.02506637573242\n",
      "epoch 22, MSE: 22.468549728393555\n",
      "epoch 23, MSE: 30.825918197631836\n",
      "epoch 24, MSE: 40.58780288696289\n",
      "epoch 25, MSE: 48.1026611328125\n",
      "epoch 26, MSE: 34.92483139038086\n",
      "epoch 27, MSE: 27.762123107910156\n",
      "epoch 28, MSE: 33.257694244384766\n",
      "epoch 29, MSE: 42.98944091796875\n",
      "epoch 30, MSE: 34.704261779785156\n",
      "epoch 31, MSE: 20.362733840942383\n",
      "epoch 32, MSE: 43.521507263183594\n",
      "epoch 33, MSE: 37.15214538574219\n",
      "epoch 34, MSE: 44.240596771240234\n",
      "epoch 35, MSE: 28.46075439453125\n",
      "epoch 36, MSE: 25.976545333862305\n",
      "epoch 37, MSE: 34.43761444091797\n",
      "epoch 38, MSE: 33.13810348510742\n",
      "epoch 39, MSE: 32.19691467285156\n",
      "r2-score:0.936673218939184\n",
      "MSE: 38.845, RMSE: 6.233\n"
     ]
    }
   ],
   "source": [
    "path = \"/home/brechtl/OneDrive/Lessen/AI Frameworks/Project/Data/Math_Test_Results_Cleaned.csv\"\n",
    "train_dl, test_dl = prepare_data(path)\n",
    "\n",
    "# define the network\n",
    "model = Regressor(14)\n",
    "\n",
    "# train the model\n",
    "train_model(train_dl, model)\n",
    "# evaluate the model\n",
    "mse = evaluate_model(test_dl, model)\n",
    "print('MSE: %.3f, RMSE: %.3f' % (mse, np.sqrt(mse)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ea7f11",
   "metadata": {},
   "source": [
    "That's it! We got a good result finally.  \n",
    "The MSE does not look that stable but we are using mini-batches so that's probably the why."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2c1d27",
   "metadata": {},
   "source": [
    "#### Test the model with predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "192c3de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(row, model):\n",
    "    # make prediction\n",
    "    yhat = model(row)\n",
    "    # retrieve numpy array\n",
    "    yhat = yhat.detach().numpy()\n",
    "    return yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "fe08c98f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target:687, prediction:684\n",
      "target:718, prediction:719\n",
      "target:672, prediction:660\n",
      "target:686, prediction:690\n",
      "target:662, prediction:660\n",
      "target:644, prediction:649\n",
      "target:644, prediction:650\n",
      "target:698, prediction:700\n",
      "target:696, prediction:701\n",
      "target:674, prediction:682\n",
      "target:651, prediction:657\n",
      "target:678, prediction:675\n",
      "target:607, prediction:613\n",
      "target:650, prediction:646\n",
      "target:655, prediction:644\n",
      "target:700, prediction:688\n",
      "target:705, prediction:699\n",
      "target:659, prediction:656\n",
      "target:685, prediction:682\n",
      "target:684, prediction:677\n",
      "target:675, prediction:670\n",
      "target:701, prediction:698\n",
      "target:707, prediction:706\n",
      "target:681, prediction:679\n",
      "target:725, prediction:716\n",
      "target:714, prediction:698\n",
      "target:671, prediction:669\n",
      "target:697, prediction:697\n",
      "target:709, prediction:710\n",
      "target:637, prediction:645\n",
      "target:677, prediction:667\n",
      "target:654, prediction:654\n",
      "target:686, prediction:691\n",
      "target:691, prediction:697\n",
      "target:685, prediction:690\n",
      "target:647, prediction:647\n",
      "target:684, prediction:684\n",
      "target:692, prediction:691\n",
      "target:694, prediction:692\n",
      "target:656, prediction:654\n",
      "target:705, prediction:704\n",
      "target:708, prediction:705\n",
      "target:695, prediction:700\n",
      "target:647, prediction:653\n",
      "target:674, prediction:672\n",
      "target:702, prediction:702\n",
      "target:672, prediction:668\n",
      "target:677, prediction:685\n",
      "target:665, prediction:663\n",
      "target:651, prediction:647\n",
      "target:675, prediction:673\n",
      "target:684, prediction:684\n",
      "target:668, prediction:665\n",
      "target:682, prediction:681\n",
      "target:646, prediction:647\n",
      "target:642, prediction:648\n",
      "target:685, prediction:684\n",
      "target:671, prediction:670\n",
      "target:662, prediction:667\n",
      "target:705, prediction:715\n",
      "target:652, prediction:656\n",
      "target:688, prediction:683\n",
      "target:683, prediction:686\n",
      "target:703, prediction:706\n",
      "target:601, prediction:603\n",
      "target:689, prediction:683\n",
      "target:652, prediction:657\n",
      "target:667, prediction:672\n",
      "target:686, prediction:686\n",
      "target:668, prediction:676\n"
     ]
    }
   ],
   "source": [
    "for inputs, targets in test_dl:\n",
    "    yhat = predict(inputs[22], model)\n",
    "    print(\"target:\" + str(round(targets[22].item())) + \", prediction:\" + str(round(yhat.item())))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b65c0c",
   "metadata": {},
   "source": [
    "#### Complexity\n",
    "Now it's possible again to make the model more complex because the simple model is working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "e7415db8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, MSE: 7937.3515625\n",
      "epoch 1, MSE: 2971.417724609375\n",
      "epoch 2, MSE: 318.1760559082031\n",
      "epoch 3, MSE: 39.05628204345703\n",
      "epoch 4, MSE: 470.8504333496094\n",
      "epoch 5, MSE: 35.594520568847656\n",
      "epoch 6, MSE: 32.580810546875\n",
      "epoch 7, MSE: 35.680782318115234\n",
      "epoch 8, MSE: 108.84716033935547\n",
      "epoch 9, MSE: 147.00631713867188\n",
      "epoch 10, MSE: 49.81734085083008\n",
      "epoch 11, MSE: 47.595455169677734\n",
      "epoch 12, MSE: 33.94655227661133\n",
      "epoch 13, MSE: 15.581425666809082\n",
      "epoch 14, MSE: 35.353904724121094\n",
      "epoch 15, MSE: 23.311288833618164\n",
      "epoch 16, MSE: 25.563072204589844\n",
      "epoch 17, MSE: 42.04293441772461\n",
      "epoch 18, MSE: 16.433443069458008\n",
      "epoch 19, MSE: 85.72439575195312\n",
      "epoch 20, MSE: 30.81047248840332\n",
      "epoch 21, MSE: 15.667374610900879\n",
      "epoch 22, MSE: 33.17586898803711\n",
      "epoch 23, MSE: 37.800376892089844\n",
      "epoch 24, MSE: 24.753286361694336\n",
      "epoch 25, MSE: 40.14764404296875\n",
      "epoch 26, MSE: 25.925565719604492\n",
      "epoch 27, MSE: 19.724285125732422\n",
      "epoch 28, MSE: 14.297674179077148\n",
      "epoch 29, MSE: 28.96722412109375\n",
      "epoch 30, MSE: 20.449909210205078\n",
      "epoch 31, MSE: 30.62495994567871\n",
      "epoch 32, MSE: 27.299989700317383\n",
      "epoch 33, MSE: 22.20060157775879\n",
      "epoch 34, MSE: 23.133405685424805\n",
      "epoch 35, MSE: 38.1994743347168\n",
      "epoch 36, MSE: 26.47826385498047\n",
      "epoch 37, MSE: 26.29740333557129\n",
      "epoch 38, MSE: 31.668489456176758\n",
      "epoch 39, MSE: 27.410261154174805\n",
      "r2-score:0.9508667491620282\n",
      "MSE: 26.440, RMSE: 5.142\n"
     ]
    }
   ],
   "source": [
    "def train_model(train_dl, model):\n",
    "    # define the optimization\n",
    "    criterion = torch.nn.MSELoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.0001)\n",
    "    # enumerate epochs\n",
    "    for epoch in range(40):\n",
    "        # enumerate mini batches\n",
    "        for i, (inputs, targets) in enumerate(train_dl):\n",
    "            # clear the gradients\n",
    "            optimizer.zero_grad()\n",
    "            # compute the model output\n",
    "            yhat = model(inputs)\n",
    "            # calculate loss\n",
    "            loss = criterion(yhat, targets)\n",
    "            # credit assignment\n",
    "            loss.backward()\n",
    "            # update model weights\n",
    "            optimizer.step()\n",
    "        print('epoch {}, MSE: {}'.format(epoch, loss))\n",
    "\n",
    "        \n",
    "class Regressor(torch.nn.Module):\n",
    "    # define model elements\n",
    "    def __init__(self, n_inputs):\n",
    "        super(Regressor, self).__init__()\n",
    "        # input to first hidden layer\n",
    "        self.hidden1 = torch.nn.Linear(n_inputs, 10)\n",
    "        self.act1 = torch.nn.ReLU()\n",
    "        self.hidden2 = torch.nn.Linear(10, 10)\n",
    "        self.act2 = torch.nn.ReLU()\n",
    "        self.hidden3 = torch.nn.Linear(10,1)\n",
    "\n",
    "    # forward propagate input\n",
    "    def forward(self, X):\n",
    "        # input to first hidden layer\n",
    "        X = self.hidden1(X)\n",
    "        X = self.act1(X)\n",
    "        X = self.hidden2(X)\n",
    "        X = self.act2(X)\n",
    "        X = self.hidden3(X)\n",
    "        return X\n",
    "\n",
    "path = \"/home/brechtl/OneDrive/Lessen/AI Frameworks/Project/Data/Math_Test_Results_Cleaned.csv\"\n",
    "train_dl, test_dl = prepare_data(path)\n",
    "\n",
    "# define the network\n",
    "model = Regressor(14)\n",
    "\n",
    "# train the model\n",
    "train_model(train_dl, model)\n",
    "# evaluate the model\n",
    "mse = evaluate_model(test_dl, model)\n",
    "print('MSE: %.3f, RMSE: %.3f' % (mse, np.sqrt(mse)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "c491c674",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target:668, prediction:674\n",
      "target:648, prediction:651\n",
      "target:699, prediction:704\n",
      "target:674, prediction:674\n",
      "target:658, prediction:664\n",
      "target:622, prediction:626\n",
      "target:602, prediction:612\n",
      "target:661, prediction:665\n",
      "target:653, prediction:647\n",
      "target:641, prediction:640\n",
      "target:691, prediction:700\n",
      "target:686, prediction:682\n",
      "target:675, prediction:680\n",
      "target:672, prediction:671\n",
      "target:693, prediction:695\n",
      "target:681, prediction:684\n",
      "target:644, prediction:641\n",
      "target:662, prediction:663\n",
      "target:690, prediction:688\n",
      "target:682, prediction:683\n",
      "target:662, prediction:670\n",
      "target:682, prediction:678\n",
      "target:631, prediction:638\n",
      "target:672, prediction:673\n",
      "target:694, prediction:698\n",
      "target:692, prediction:696\n",
      "target:687, prediction:686\n",
      "target:666, prediction:671\n",
      "target:665, prediction:669\n",
      "target:655, prediction:662\n",
      "target:662, prediction:663\n",
      "target:673, prediction:676\n",
      "target:655, prediction:658\n",
      "target:642, prediction:646\n",
      "target:652, prediction:642\n",
      "target:621, prediction:608\n",
      "target:670, prediction:671\n",
      "target:613, prediction:611\n",
      "target:710, prediction:728\n",
      "target:693, prediction:700\n",
      "target:657, prediction:660\n",
      "target:671, prediction:678\n",
      "target:668, prediction:672\n",
      "target:689, prediction:689\n",
      "target:693, prediction:702\n",
      "target:683, prediction:688\n",
      "target:682, prediction:675\n",
      "target:683, prediction:677\n",
      "target:686, prediction:688\n",
      "target:632, prediction:632\n",
      "target:640, prediction:644\n",
      "target:681, prediction:686\n",
      "target:702, prediction:700\n",
      "target:671, prediction:676\n",
      "target:628, prediction:635\n",
      "target:673, prediction:673\n",
      "target:690, prediction:691\n",
      "target:682, prediction:672\n",
      "target:682, prediction:681\n",
      "target:659, prediction:663\n",
      "target:696, prediction:702\n",
      "target:688, prediction:694\n",
      "target:671, prediction:672\n",
      "target:674, prediction:673\n",
      "target:695, prediction:699\n",
      "target:622, prediction:619\n",
      "target:710, prediction:715\n",
      "target:719, prediction:715\n",
      "target:682, prediction:683\n",
      "target:691, prediction:697\n"
     ]
    }
   ],
   "source": [
    "for inputs, targets in test_dl:\n",
    "    yhat = predict(inputs[22], model)\n",
    "    print(\"target:\" + str(round(targets[22].item())) + \", prediction:\" + str(round(yhat.item())))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f8dd9e",
   "metadata": {},
   "source": [
    "It does not look that the accuracy will get any better after a lot of trying and parameter tuning.  \n",
    "I tried a library called ray for the paramter tuning as well but got no good results from this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "266d7275",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2023-01-19 16:35:51</td></tr>\n",
       "<tr><td>Running for: </td><td>00:00:16.56        </td></tr>\n",
       "<tr><td>Memory:      </td><td>10.0/15.6 GiB      </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using FIFO scheduling algorithm.<br>Resources requested: 0/4 CPUs, 0/1 GPUs, 0.0/3.78 GiB heap, 0.0/1.89 GiB objects (0.0/1.0 accelerator_type:G)\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name             </th><th>status    </th><th>loc                </th><th style=\"text-align: right;\">    lr</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_model_eac42_00000</td><td>TERMINATED</td><td>192.168.0.144:83222</td><td style=\"text-align: right;\">0.0001</td></tr>\n",
       "<tr><td>train_model_eac42_00001</td><td>TERMINATED</td><td>192.168.0.144:83276</td><td style=\"text-align: right;\">1e-05 </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_model pid=83222)\u001b[0m epoch 0, MSE: 13268.78515625\n",
      "\u001b[2m\u001b[36m(train_model pid=83222)\u001b[0m epoch 1, MSE: 476.96966552734375\n",
      "\u001b[2m\u001b[36m(train_model pid=83222)\u001b[0m epoch 2, MSE: 276.8553466796875\n",
      "\u001b[2m\u001b[36m(train_model pid=83222)\u001b[0m epoch 3, MSE: 47.89863586425781\n",
      "\u001b[2m\u001b[36m(train_model pid=83222)\u001b[0m epoch 4, MSE: 46.28987121582031\n",
      "\u001b[2m\u001b[36m(train_model pid=83222)\u001b[0m epoch 5, MSE: 128.84844970703125\n",
      "\u001b[2m\u001b[36m(train_model pid=83222)\u001b[0m epoch 6, MSE: 202.67715454101562\n",
      "\u001b[2m\u001b[36m(train_model pid=83222)\u001b[0m epoch 7, MSE: 314.7962341308594\n",
      "\u001b[2m\u001b[36m(train_model pid=83222)\u001b[0m epoch 8, MSE: 26.315553665161133\n",
      "\u001b[2m\u001b[36m(train_model pid=83222)\u001b[0m epoch 9, MSE: 26.09436798095703\n",
      "\u001b[2m\u001b[36m(train_model pid=83222)\u001b[0m epoch 10, MSE: 17.933006286621094\n",
      "\u001b[2m\u001b[36m(train_model pid=83222)\u001b[0m epoch 11, MSE: 33.11283874511719\n",
      "\u001b[2m\u001b[36m(train_model pid=83276)\u001b[0m epoch 0, MSE: 2760.06884765625\n",
      "\u001b[2m\u001b[36m(train_model pid=83222)\u001b[0m epoch 12, MSE: 37.972023010253906\n",
      "\u001b[2m\u001b[36m(train_model pid=83222)\u001b[0m epoch 13, MSE: 18.201204299926758\n",
      "\u001b[2m\u001b[36m(train_model pid=83276)\u001b[0m epoch 1, MSE: 257.9718933105469\n",
      "\u001b[2m\u001b[36m(train_model pid=83222)\u001b[0m epoch 14, MSE: 101.10860443115234\n",
      "\u001b[2m\u001b[36m(train_model pid=83276)\u001b[0m epoch 2, MSE: 57.83163070678711\n",
      "\u001b[2m\u001b[36m(train_model pid=83222)\u001b[0m epoch 15, MSE: 26.646421432495117\n",
      "\u001b[2m\u001b[36m(train_model pid=83276)\u001b[0m epoch 3, MSE: 28.56505584716797\n",
      "\u001b[2m\u001b[36m(train_model pid=83222)\u001b[0m epoch 16, MSE: 18.34915542602539\n",
      "\u001b[2m\u001b[36m(train_model pid=83276)\u001b[0m epoch 4, MSE: 85.15433502197266\n",
      "\u001b[2m\u001b[36m(train_model pid=83222)\u001b[0m epoch 17, MSE: 23.434762954711914\n",
      "\u001b[2m\u001b[36m(train_model pid=83276)\u001b[0m epoch 5, MSE: 29.2857666015625\n",
      "\u001b[2m\u001b[36m(train_model pid=83222)\u001b[0m epoch 18, MSE: 33.64792251586914\n",
      "\u001b[2m\u001b[36m(train_model pid=83276)\u001b[0m epoch 6, MSE: 26.918132781982422\n",
      "\u001b[2m\u001b[36m(train_model pid=83222)\u001b[0m epoch 19, MSE: 19.465007781982422\n",
      "\u001b[2m\u001b[36m(train_model pid=83276)\u001b[0m epoch 7, MSE: 28.26063346862793\n",
      "\u001b[2m\u001b[36m(train_model pid=83222)\u001b[0m epoch 20, MSE: 14.990915298461914\n",
      "\u001b[2m\u001b[36m(train_model pid=83276)\u001b[0m epoch 8, MSE: 40.76834487915039\n",
      "\u001b[2m\u001b[36m(train_model pid=83222)\u001b[0m epoch 21, MSE: 87.73020935058594\n",
      "\u001b[2m\u001b[36m(train_model pid=83276)\u001b[0m epoch 9, MSE: 35.323184967041016\n",
      "\u001b[2m\u001b[36m(train_model pid=83222)\u001b[0m epoch 22, MSE: 30.60831642150879\n",
      "\u001b[2m\u001b[36m(train_model pid=83276)\u001b[0m epoch 10, MSE: 47.79505157470703\n",
      "\u001b[2m\u001b[36m(train_model pid=83222)\u001b[0m epoch 23, MSE: 18.82942771911621\n",
      "\u001b[2m\u001b[36m(train_model pid=83276)\u001b[0m epoch 11, MSE: 29.779935836791992\n",
      "\u001b[2m\u001b[36m(train_model pid=83222)\u001b[0m epoch 24, MSE: 27.790714263916016\n",
      "\u001b[2m\u001b[36m(train_model pid=83276)\u001b[0m epoch 12, MSE: 40.323890686035156\n",
      "\u001b[2m\u001b[36m(train_model pid=83222)\u001b[0m epoch 25, MSE: 39.917171478271484\n",
      "\u001b[2m\u001b[36m(train_model pid=83276)\u001b[0m epoch 13, MSE: 29.651897430419922\n",
      "\u001b[2m\u001b[36m(train_model pid=83222)\u001b[0m epoch 26, MSE: 25.043079376220703\n",
      "\u001b[2m\u001b[36m(train_model pid=83276)\u001b[0m epoch 14, MSE: 42.672061920166016\n",
      "\u001b[2m\u001b[36m(train_model pid=83222)\u001b[0m epoch 27, MSE: 21.784461975097656\n",
      "\u001b[2m\u001b[36m(train_model pid=83276)\u001b[0m epoch 15, MSE: 36.46796798706055\n",
      "\u001b[2m\u001b[36m(train_model pid=83222)\u001b[0m epoch 28, MSE: 41.155269622802734\n",
      "\u001b[2m\u001b[36m(train_model pid=83276)\u001b[0m epoch 16, MSE: 36.44541931152344\n",
      "\u001b[2m\u001b[36m(train_model pid=83222)\u001b[0m epoch 29, MSE: 26.10830307006836\n",
      "\u001b[2m\u001b[36m(train_model pid=83276)\u001b[0m epoch 17, MSE: 26.477413177490234\n",
      "\u001b[2m\u001b[36m(train_model pid=83222)\u001b[0m epoch 30, MSE: 75.12205505371094\n",
      "\u001b[2m\u001b[36m(train_model pid=83276)\u001b[0m epoch 18, MSE: 30.337797164916992\n",
      "\u001b[2m\u001b[36m(train_model pid=83276)\u001b[0m epoch 19, MSE: 18.5805606842041\n",
      "\u001b[2m\u001b[36m(train_model pid=83222)\u001b[0m epoch 31, MSE: 33.171348571777344\n",
      "\u001b[2m\u001b[36m(train_model pid=83276)\u001b[0m epoch 20, MSE: 49.859004974365234\n",
      "\u001b[2m\u001b[36m(train_model pid=83222)\u001b[0m epoch 32, MSE: 17.912189483642578\n",
      "\u001b[2m\u001b[36m(train_model pid=83276)\u001b[0m epoch 21, MSE: 32.82651901245117\n",
      "\u001b[2m\u001b[36m(train_model pid=83222)\u001b[0m epoch 33, MSE: 12.657470703125\n",
      "\u001b[2m\u001b[36m(train_model pid=83276)\u001b[0m epoch 22, MSE: 16.06317138671875\n",
      "\u001b[2m\u001b[36m(train_model pid=83222)\u001b[0m epoch 34, MSE: 84.55919647216797\n",
      "\u001b[2m\u001b[36m(train_model pid=83276)\u001b[0m epoch 23, MSE: 23.785249710083008\n",
      "\u001b[2m\u001b[36m(train_model pid=83222)\u001b[0m epoch 35, MSE: 21.518800735473633\n",
      "\u001b[2m\u001b[36m(train_model pid=83276)\u001b[0m epoch 24, MSE: 26.469022750854492\n",
      "\u001b[2m\u001b[36m(train_model pid=83222)\u001b[0m epoch 36, MSE: 9.809897422790527\n",
      "\u001b[2m\u001b[36m(train_model pid=83276)\u001b[0m epoch 25, MSE: 26.79017448425293\n",
      "\u001b[2m\u001b[36m(train_model pid=83222)\u001b[0m epoch 37, MSE: 11.851308822631836\n",
      "\u001b[2m\u001b[36m(train_model pid=83276)\u001b[0m epoch 26, MSE: 28.07650375366211\n",
      "\u001b[2m\u001b[36m(train_model pid=83222)\u001b[0m epoch 38, MSE: 19.523595809936523\n",
      "\u001b[2m\u001b[36m(train_model pid=83276)\u001b[0m epoch 27, MSE: 24.099029541015625\n",
      "Trial train_model_eac42_00000 completed. Last result: \n",
      "\u001b[2m\u001b[36m(train_model pid=83222)\u001b[0m epoch 39, MSE: 25.359310150146484\n",
      "\u001b[2m\u001b[36m(train_model pid=83276)\u001b[0m epoch 28, MSE: 30.250885009765625\n",
      "\u001b[2m\u001b[36m(train_model pid=83276)\u001b[0m epoch 29, MSE: 32.767452239990234\n",
      "\u001b[2m\u001b[36m(train_model pid=83276)\u001b[0m epoch 30, MSE: 27.018245697021484\n",
      "\u001b[2m\u001b[36m(train_model pid=83276)\u001b[0m epoch 31, MSE: 22.333906173706055\n",
      "\u001b[2m\u001b[36m(train_model pid=83276)\u001b[0m epoch 32, MSE: 25.164405822753906\n",
      "\u001b[2m\u001b[36m(train_model pid=83276)\u001b[0m epoch 33, MSE: 45.87195587158203\n",
      "\u001b[2m\u001b[36m(train_model pid=83276)\u001b[0m epoch 34, MSE: 28.649320602416992\n",
      "\u001b[2m\u001b[36m(train_model pid=83276)\u001b[0m epoch 35, MSE: 22.015607833862305\n",
      "\u001b[2m\u001b[36m(train_model pid=83276)\u001b[0m epoch 36, MSE: 30.14832305908203\n",
      "\u001b[2m\u001b[36m(train_model pid=83276)\u001b[0m epoch 37, MSE: 16.23286247253418\n",
      "\u001b[2m\u001b[36m(train_model pid=83276)\u001b[0m epoch 38, MSE: 18.090715408325195\n",
      "Trial train_model_eac42_00001 completed. Last result: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-19 16:35:52,094\tINFO tune.py:762 -- Total run time: 16.70 seconds (16.56 seconds for the tuning loop).\n",
      "2023-01-19 16:35:52,096\tWARNING experiment_analysis.py:627 -- Could not find best trial. Did you pass the correct `metric` parameter?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_model pid=83276)\u001b[0m epoch 39, MSE: 18.34276008605957\n",
      "Best config:  None\n"
     ]
    }
   ],
   "source": [
    "from ray import tune\n",
    "import ray.rllib.algorithms.ppo as ppo\n",
    "\n",
    "def train_model(config):\n",
    "    model = Regressor(14)\n",
    "    path = \"/home/brechtl/OneDrive/Lessen/AI Frameworks/Project/Data/Math_Test_Results_Cleaned.csv\"\n",
    "    train_dl, test_dl = prepare_data(path)\n",
    "    # define the network\n",
    "    \n",
    "    # define the optimization\n",
    "    criterion = torch.nn.MSELoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=config[\"lr\"])\n",
    "    # enumerate epochs\n",
    "    for epoch in range(40):\n",
    "        # enumerate mini batches\n",
    "        for i, (inputs, targets) in enumerate(train_dl):\n",
    "            # clear the gradients\n",
    "            optimizer.zero_grad()\n",
    "            # compute the model output\n",
    "            yhat = model(inputs)\n",
    "            # calculate loss\n",
    "            loss = criterion(yhat, targets)\n",
    "            # credit assignment\n",
    "            loss.backward()\n",
    "            # update model weights\n",
    "            optimizer.step()\n",
    "        print('epoch {}, MSE: {}'.format(epoch, loss))\n",
    "\n",
    "result = tune.run(train_model, config={\"lr\": tune.grid_search([0.0001, 0.00001])}, verbose=3)\n",
    "\n",
    "print(\"Best config: \", result.get_best_config(metric=\"loss\", mode=\"min\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0170aa3e",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "I would definitely choose the SVM model for this case because it is stable, fast and accurate. A neural network is not always the right choice for tabular data and in my case, it makes things harder and more complex without adding value."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiframeworks",
   "language": "python",
   "name": "aiframeworks"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
